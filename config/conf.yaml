train:
  num_epochs: 3
  accum_iter: 10
  base_lr: 1.0
  batch_size: 16
  distributed: False
  label_smoothing: 0.1

max_tokens: 16_000
max_padding: 72
warmup: 3000
device: "cpu"
data_slice: "200"
vocab_data_slice: ${data_slice}

log_frequency: 10
file_prefix: "wmt16_model"
model_path: "wmt16_model_final.pt"
run_name: transformer-${now:%Y-%m-%d-%H-%M}
project: "transformer"

model:
  n: 6
  d_model: 512
  d_ff: 2048
  h: 8
  dropout: 0.1
